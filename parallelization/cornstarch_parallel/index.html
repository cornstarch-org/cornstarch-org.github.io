
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Distributed Multimodal LLM training framework">
      
      
        <meta name="author" content="Cornstarch team">
      
      
      
        <link rel="prev" href="../ddp_fsdp/">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>Using Cornstarch 5D Parallelism - Cornstarch Project</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="amber" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#creating-multimodalparallelplugin" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Cornstarch Project" class="md-header__button md-logo" aria-label="Cornstarch Project" data-md-component="logo">
      
  <img src="../../assets/images/cornstarch.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Cornstarch Project
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Using Cornstarch 5D Parallelism
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/cornstarch-org/Cornstarch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    cornstarch-org/Cornstarch
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Cornstarch

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../getting_started/installation/" class="md-tabs__link">
        
  
    
  
  Installation

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../using_cornstarch/creating_mllm/" class="md-tabs__link">
          
  
  Using Cornstarch

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  Distributed Training

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Cornstarch Project" class="md-nav__button md-logo" aria-label="Cornstarch Project" data-md-component="logo">
      
  <img src="../../assets/images/cornstarch.svg" alt="logo">

    </a>
    Cornstarch Project
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/cornstarch-org/Cornstarch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    cornstarch-org/Cornstarch
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cornstarch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Using Cornstarch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Using Cornstarch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../using_cornstarch/creating_mllm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Creating a MLLM model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../using_cornstarch/preprocessing_inputs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocessing inputs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../using_cornstarch/training_mllm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training a MLLM model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Distributed Training
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Distributed Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ddp_fsdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using DDP/FSDP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Using Cornstarch 5D Parallelism
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Using Cornstarch 5D Parallelism
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#creating-multimodalparallelplugin" class="md-nav__link">
    <span class="md-ellipsis">
      Creating MultimodalParallelPlugin
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specifying-parallelization" class="md-nav__link">
    <span class="md-ellipsis">
      Specifying Parallelization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Specifying Parallelization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Parallelism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Context Parallelism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pipeline-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Pipeline Parallelism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Data Parallelism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modality-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Modality Parallelism
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-parallelized-module" class="md-nav__link">
    <span class="md-ellipsis">
      Running Parallelized Module
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#creating-multimodalparallelplugin" class="md-nav__link">
    <span class="md-ellipsis">
      Creating MultimodalParallelPlugin
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specifying-parallelization" class="md-nav__link">
    <span class="md-ellipsis">
      Specifying Parallelization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Specifying Parallelization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Parallelism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Context Parallelism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pipeline-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Pipeline Parallelism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Data Parallelism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modality-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Modality Parallelism
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-parallelized-module" class="md-nav__link">
    <span class="md-ellipsis">
      Running Parallelized Module
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Using Cornstarch 5D Parallelism</h1>

<div class="admonition info">
<p class="admonition-title">Info</p>
<p><a href="https://github.com/cornstarch-org/Cornstarch">Cornstarch repository</a> provides an end-to-end example
in <a href="https://github.com/cornstarch-org/Cornstarch/blob/main/examples/distributed/run_vlm_hybrid.py"><code>examples/distributed/run_vlm_hybrid.py</code></a>.</p>
</div>
<p>Using FSDP/DDP only may not be scalable depending on the infrastructure (e.g. slow inter-node networking).
Cornstarch provides 5D parallelism (data parallelism, tensor parallelism, pipeline parallelism, context parallelism, and modality parallelism).</p>
<h2 id="creating-multimodalparallelplugin">Creating <code>MultimodalParallelPlugin</code></h2>
<p>Cornstarch allows per-modality parallelization specification using modular information in <code>MultimodalModel</code>.
<a href="/using_cornstarch/creating_mllm">Recall</a> that a <code>MultimodalModel</code> is organized with multiple <code>ModalEncoderModule</code>s, one per modality encoder:</p>
<div class="language-py highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="kn">from</span> <span class="nn">cornstarch.models.multimodal_language_model</span> <span class="kn">import</span> <span class="n">ModalEncoderModule</span><span class="p">,</span> <span class="n">MultimodalModel</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="n">vision_encoder</span> <span class="o">=</span> <span class="o">...</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="n">audio_encoder</span> <span class="o">=</span> <span class="o">...</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="n">llm</span> <span class="o">=</span> <span class="o">...</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="n">mllm</span> <span class="o">=</span> <span class="n">MultimodalModel</span><span class="p">(</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="n">encoders</span><span class="o">=</span><span class="p">{</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="s2">&quot;vision&quot;</span><span class="p">:</span> <span class="n">ModalEncoderModule</span><span class="p">(</span><span class="n">vision_encoder</span><span class="p">),</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="s2">&quot;audio&quot;</span><span class="p">:</span> <span class="n">ModalEncoderModule</span><span class="p">(</span><span class="n">audio_encoder</span><span class="p">),</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="p">},</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="n">language_model</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>Cornstarch provides the same architecture to specify parallelization per modality encoder and llm:</p>
<div class="language-py highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-1-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-1-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-1-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-1-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-1-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-1-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-1-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-1-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-1-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-1-10">10</a></span>
<span class="normal"><a href="#__codelineno-1-11">11</a></span>
<span class="normal"><a href="#__codelineno-1-12">12</a></span>
<span class="normal"><a href="#__codelineno-1-13">13</a></span>
<span class="normal"><a href="#__codelineno-1-14">14</a></span>
<span class="normal"><a href="#__codelineno-1-15">15</a></span>
<span class="normal"><a href="#__codelineno-1-16">16</a></span>
<span class="normal"><a href="#__codelineno-1-17">17</a></span>
<span class="normal"><a href="#__codelineno-1-18">18</a></span>
<span class="normal"><a href="#__codelineno-1-19">19</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="kn">from</span> <span class="nn">cornstarch.plugin.multimodal_parallel_plugin</span> <span class="kn">import</span> <span class="n">ModalParallelPlugin</span><span class="p">,</span> <span class="n">MultimodalParallelPlugin</span>
<a id="__codelineno-1-2" name="__codelineno-1-2"></a><span class="kn">from</span> <span class="nn">colossalai.booster</span> <span class="kn">import</span> <span class="n">Booster</span>
<a id="__codelineno-1-3" name="__codelineno-1-3"></a>
<a id="__codelineno-1-4" name="__codelineno-1-4"></a><span class="n">vision_encoder_plugin</span> <span class="o">=</span> <span class="n">ModalParallelPlugin</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<a id="__codelineno-1-5" name="__codelineno-1-5"></a><span class="n">audio_encoder_plugin</span> <span class="o">=</span> <span class="n">ModalParallelPlugin</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<a id="__codelineno-1-6" name="__codelineno-1-6"></a><span class="n">language_model_plugin</span> <span class="o">=</span> <span class="n">ModalParallelPlugin</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<a id="__codelineno-1-7" name="__codelineno-1-7"></a>
<a id="__codelineno-1-8" name="__codelineno-1-8"></a><span class="hll"><span class="n">mllm_plugin</span> <span class="o">=</span> <span class="n">MultimodalParallelPlugin</span><span class="p">(</span>
</span><a id="__codelineno-1-9" name="__codelineno-1-9"></a><span class="hll">    <span class="n">encoder_plugins</span><span class="o">=</span><span class="p">{</span>
</span><a id="__codelineno-1-10" name="__codelineno-1-10"></a><span class="hll">        <span class="s2">&quot;vision&quot;</span><span class="p">:</span> <span class="n">vision_encoder_plugin</span><span class="p">,</span>
</span><a id="__codelineno-1-11" name="__codelineno-1-11"></a><span class="hll">        <span class="s2">&quot;audio&quot;</span><span class="p">:</span> <span class="n">audio_encoder_plugin</span><span class="p">,</span>
</span><a id="__codelineno-1-12" name="__codelineno-1-12"></a><span class="hll">    <span class="p">},</span>
</span><a id="__codelineno-1-13" name="__codelineno-1-13"></a><span class="hll">    <span class="n">language_model_plugin</span><span class="o">=</span><span class="n">language_model_plugin</span><span class="p">,</span>
</span><a id="__codelineno-1-14" name="__codelineno-1-14"></a><span class="hll">    <span class="o">...</span>
</span><a id="__codelineno-1-15" name="__codelineno-1-15"></a><span class="hll"><span class="p">)</span>
</span><a id="__codelineno-1-16" name="__codelineno-1-16"></a>
<a id="__codelineno-1-17" name="__codelineno-1-17"></a><span class="c1"># Parallelize the model.</span>
<a id="__codelineno-1-18" name="__codelineno-1-18"></a><span class="n">booster</span> <span class="o">=</span> <span class="n">Booster</span><span class="p">(</span><span class="n">plugin</span><span class="o">=</span><span class="n">mllm_plugin</span><span class="p">)</span>
<a id="__codelineno-1-19" name="__codelineno-1-19"></a><span class="n">parallel_mllm</span><span class="p">,</span> <span class="n">_</span><span class="o">*</span> <span class="o">=</span> <span class="n">booster</span><span class="o">.</span><span class="n">boost</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">mllm</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All encoders defined when creating <code>MultimodalModel</code> should have its corresponding plugin, otherwise an exception will be raised during parallelization.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Parallelization is done lazily; the model is not parallelized until <code>colossalai.booster.Booster.boost()</code> is called.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently using <code>MultimodalParallelPlugin</code> forces to use pipeline parallelism, as encoders and the LLM should be pipelined in different stages.</p>
</div>
<p>The structure of <code>MultimodalParallelPlugin</code> exactly follows that of <code>MultimodalModel</code>.
Each encoder and the language model must have their own <code>ModalParallelPlugin</code>, which specifies how each modality should be parallelized.</p>
<h2 id="specifying-parallelization">Specifying Parallelization</h2>
<p>Each <code>ModalParallelPlugin</code> has four arguments for parallel configurations: <code>tp_size</code>, <code>sp_size</code>, <code>sequence_parallelism_mode</code>, and <code>pipeline_template</code>.
The arguments are mapped to the following three parallel dimensions:</p>
<ul>
<li>Tensor Parallelism (TP): <code>tp_size</code></li>
<li>Context Parallelism (CP): <code>sp_size</code>, <code>sequence_parallelism_mode</code>, and <code>context_parallel_distribution_mode</code>.</li>
<li>Pipeline Parallelism (PP): <code>pipeline_template</code></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Cornstarch uses the term <code>sequence_parallelism</code> for backward compatibility: which is used by colossalai.
Cornstarch does not support Megatron's sequence parallelism that is used as a combination of tensor parallelism.</p>
</div>
<h3 id="tensor-parallelism">Tensor Parallelism</h3>
<p>All embedding and linear layers are partitioned to tensor parallel ranks.
For attention layers, it is partitioned in head dimension; the number of heads of a model should be divisible to <code>tp_size</code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently specifying different number of <code>tp_size</code> to different encoders or LLM is not supported.</p>
</div>
<h3 id="context-parallelism">Context Parallelism</h3>
<p>Cornstarch supports Ulysses all-to-all style context parallelism and Llama context parallelism (head-by-head parallelism).
You can set <code>sequence_parallelism_mode</code> to <code>all_to_all</code> (Ulysses) or <code>ring_attn</code> (llama CP) to choose the context parallelism mechanism.</p>
<p>Encoders and the LLM can have different number of <code>sp_size</code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code>sp_size &lt;= 1</code>, <code>sequence_parallelism_mode</code> is ignored.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently context parallelism is supported only for the LLM.</p>
</div>
<p>Context parallelism split sequeneces into subsets of tokens and distribute them into multiple ranks.
There are multiple ways of partitioning sequences and distributing tokens into ranks that Corntarch supports:</p>
<ul>
<li><code>uniform</code>: The simplest way of such partitioning. Chunk every sequence into <code>cp_world_size</code> chunks, and each rank takes one portion.</li>
<li><code>zigzag</code>: For causal attention, the amount of computation becomes imbalanced if tokens are uniformly distributed. <code>zigzag</code> partitions the sequence into <code>2 * cp_world_size</code> and each rank gets one portion from the upper half and another from the lower half, the workload sum of which is always balanced in causal attention.</li>
<li><code>makespan_min</code>: In multimodal LLM, attention should no longer be simple causal; vision tokens should attend each other regardless of their location (previous vision tokens can attend to the future vision tokens). In this form of attention, zigzag is no longer be balanced, <code>makespan_min</code> computes the amount of workloads per token block (128 tokens per block) and distributes them to minimize overall makespan (execution time). The number of tokens per rank may be different depending on the amount of workloads.</li>
</ul>
<p><img alt="" src="/assets/images/context_parallel_distribution_mode_illustration.png" /></p>
<p>The token distribution scheme can be configured by passing <code>cornstarch.shardformer.shard.shard_config.ContextParallelDistributionMode.[UNIFORM | ZIGZAG | MAKESPAN_MIN]</code> to LLM's <code>shard_config.context_parallel_distribution_mode</code>. Default is <code>MAKESPAN_MIN</code>.</p>
<h3 id="pipeline-parallelism">Pipeline Parallelism</h3>
<p>Cornstarch uses pipeline template to specify pipeline parallelism (adopted from <a href="https://dl.acm.org/doi/abs/10.1145/3600006.3613152">Oobleck</a>), instead of simply having the number of pipeline stages, to let users to specify pipeline stages more freely.</p>
<p>A way of creating a pipeline template is as follows.</p>
<ol>
<li>Get all layers required to be included in a template.</li>
<li>Split the layers into a list of sublayers properly, each of which will be a set of layers of a pipeline stage.</li>
<li>Create a <code>cornstarch.pipeline_template.PipelineTemplate</code> instance.</li>
</ol>
<p>For HF models, Cornstarch provides a way of automatically getting all layers in a model:</p>
<div class="language-py highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Getting layers from a HF model</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-2-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-2-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-2-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-2-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-2-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-2-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-2-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-2-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-2-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-2-10">10</a></span>
<span class="normal"><a href="#__codelineno-2-11">11</a></span>
<span class="normal"><a href="#__codelineno-2-12">12</a></span>
<span class="normal"><a href="#__codelineno-2-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="kn">from</span> <span class="nn">cornstarch.pipeline_template</span> <span class="kn">import</span> <span class="n">PipelineTemplate</span>
<a id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="kn">from</span> <span class="nn">transformers.models.llama</span> <span class="kn">import</span> <span class="n">LlamaForCausalLM</span>
<a id="__codelineno-2-3" name="__codelineno-2-3"></a>
<a id="__codelineno-2-4" name="__codelineno-2-4"></a><span class="n">language_model</span> <span class="o">=</span> <span class="n">LlamaForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;meta-llama/Llama-3.1-8B-Instruct&quot;</span><span class="p">)</span>
<a id="__codelineno-2-5" name="__codelineno-2-5"></a><span class="n">layers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">PipelineTemplate</span><span class="o">.</span><span class="n">get_modules</span><span class="p">(</span><span class="n">language_model</span><span class="p">)</span>
<a id="__codelineno-2-6" name="__codelineno-2-6"></a>
<a id="__codelineno-2-7" name="__codelineno-2-7"></a><span class="c1"># layers: [&quot;model.embed_tokens&quot;,</span>
<a id="__codelineno-2-8" name="__codelineno-2-8"></a><span class="c1">#   &quot;model.layers.0&quot;,</span>
<a id="__codelineno-2-9" name="__codelineno-2-9"></a><span class="c1">#   &quot;model.layers.1&quot;,</span>
<a id="__codelineno-2-10" name="__codelineno-2-10"></a><span class="c1">#   ...</span>
<a id="__codelineno-2-11" name="__codelineno-2-11"></a><span class="c1">#   &quot;model.layers.31&quot;,</span>
<a id="__codelineno-2-12" name="__codelineno-2-12"></a><span class="c1">#   &quot;model.norm&quot;,</span>
<a id="__codelineno-2-13" name="__codelineno-2-13"></a><span class="c1">#   &quot;lm_head&quot;]</span>
</code></pre></div></td></tr></table></div>
<p>Split the list of layers to however you want as <code>list[list[str]]</code>.
For example, If you want to make a 2-stage pipeline template,</p>
<div class="language-py highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-3-1">1</a></span>
<span class="normal"><a href="#__codelineno-3-2">2</a></span>
<span class="normal"><a href="#__codelineno-3-3">3</a></span>
<span class="normal"><a href="#__codelineno-3-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="n">layers_per_stage</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-3-2" name="__codelineno-3-2"></a>    <span class="n">layers</span><span class="p">[:</span><span class="mi">17</span><span class="p">],</span>
<a id="__codelineno-3-3" name="__codelineno-3-3"></a>    <span class="n">layers</span><span class="p">[</span><span class="mi">17</span><span class="p">:],</span>
<a id="__codelineno-3-4" name="__codelineno-3-4"></a><span class="p">]</span>
</code></pre></div></td></tr></table></div>
<p>which will assign the <code>embed_tokens</code> layer and first 16 decoder layers to the first pipeline stage, all the others to the second pipeline stage.</p>
<p>Now create a pipeline template:</p>
<div class="language-py highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-4-1">1</a></span>
<span class="normal"><a href="#__codelineno-4-2">2</a></span>
<span class="normal"><a href="#__codelineno-4-3">3</a></span>
<span class="normal"><a href="#__codelineno-4-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="n">pipeline_template</span> <span class="o">=</span> <span class="n">PipelineTemplate</span><span class="p">(</span>
<a id="__codelineno-4-2" name="__codelineno-4-2"></a>    <span class="n">model_name</span><span class="o">=</span><span class="n">PipelineTemplate</span><span class="o">.</span><span class="n">get_model_name</span><span class="p">(</span><span class="n">language_model</span><span class="p">),</span>
<a id="__codelineno-4-3" name="__codelineno-4-3"></a>    <span class="n">modules_per_stage</span><span class="o">=</span><span class="n">layers_per_stage</span><span class="p">,</span>
<a id="__codelineno-4-4" name="__codelineno-4-4"></a><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>which will give you a 2-stage pipeline template for <code>LlamaForCausalLM</code>:
<div class="language-py highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-5-1">1</a></span>
<span class="normal"><a href="#__codelineno-5-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="n">pipeline_template</span>
<a id="__codelineno-5-2" name="__codelineno-5-2"></a><span class="n">PipelineTemplate</span><span class="p">(</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">llama</span><span class="o">.</span><span class="n">modeling_llama</span><span class="o">.</span><span class="n">LlamaForCausalLM</span><span class="p">,</span> <span class="mi">2</span> <span class="n">stages</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Cornstarch verifies if the pipeline template is for the given unimodal model by checking its name and modules_per_stage.
It will raise an exception if a pipeline template for different model is given.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently Cornstarch pipeline parallelism does not support synchronizing tied word embeddings.</p>
</div>
<h3 id="data-parallelism">Data Parallelism</h3>
<p>Data Parallelism is not explictly specified by some arguments.
Instead, Cornstarch automatically infers how many data parallel replicas are needed by computing the number of ranks in a parallel multimodal LLM and divide the world size by it.</p>
<p><div class="language-py highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">An example of parallelization</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-6-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-6-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-6-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-6-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-6-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-6-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-6-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-6-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-6-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-6-10">10</a></span>
<span class="normal"><a href="#__codelineno-6-11">11</a></span>
<span class="normal"><a href="#__codelineno-6-12">12</a></span>
<span class="normal"><a href="#__codelineno-6-13">13</a></span>
<span class="normal"><a href="#__codelineno-6-14">14</a></span>
<span class="normal"><a href="#__codelineno-6-15">15</a></span>
<span class="normal"><a href="#__codelineno-6-16">16</a></span>
<span class="normal"><a href="#__codelineno-6-17">17</a></span>
<span class="normal"><a href="#__codelineno-6-18">18</a></span>
<span class="normal"><a href="#__codelineno-6-19">19</a></span>
<span class="normal"><a href="#__codelineno-6-20">20</a></span>
<span class="normal"><a href="#__codelineno-6-21">21</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="n">vision_encoder_plugin</span> <span class="o">=</span> <span class="n">ModalParallelPlugin</span><span class="p">(</span>
<a id="__codelineno-6-2" name="__codelineno-6-2"></a>    <span class="n">tp_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sp_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-6-3" name="__codelineno-6-3"></a>    <span class="n">pipeline_template</span><span class="o">=</span> <span class="c1"># a pipeline template with 1 stage</span>
<a id="__codelineno-6-4" name="__codelineno-6-4"></a><span class="p">)</span>
<a id="__codelineno-6-5" name="__codelineno-6-5"></a><span class="n">audio_encoder_plugin</span> <span class="o">=</span> <span class="n">ModalParallelPlugin</span><span class="p">(</span>
<a id="__codelineno-6-6" name="__codelineno-6-6"></a>    <span class="n">tp_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sp_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-6-7" name="__codelineno-6-7"></a>    <span class="n">pipeline_template</span><span class="o">=</span> <span class="c1"># a pipeline template with 1 stage</span>
<a id="__codelineno-6-8" name="__codelineno-6-8"></a><span class="p">)</span>
<a id="__codelineno-6-9" name="__codelineno-6-9"></a><span class="n">language_model_plugin</span> <span class="o">=</span> <span class="n">ModalParallelPlugin</span><span class="p">(</span>
<a id="__codelineno-6-10" name="__codelineno-6-10"></a>    <span class="n">tp_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">sp_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-6-11" name="__codelineno-6-11"></a>    <span class="n">pipeline_template</span><span class="o">=</span> <span class="c1"># a pipeline template with 3 stages</span>
<a id="__codelineno-6-12" name="__codelineno-6-12"></a><span class="p">)</span>
<a id="__codelineno-6-13" name="__codelineno-6-13"></a>
<a id="__codelineno-6-14" name="__codelineno-6-14"></a><span class="n">mllm_plugin</span> <span class="o">=</span> <span class="n">MultimodalParallelPlugin</span><span class="p">(</span>
<a id="__codelineno-6-15" name="__codelineno-6-15"></a>    <span class="n">encoder_plugins</span><span class="o">=</span><span class="p">{</span>
<a id="__codelineno-6-16" name="__codelineno-6-16"></a>        <span class="s2">&quot;vision&quot;</span><span class="p">:</span> <span class="n">vision_encoder_plugin</span><span class="p">,</span>
<a id="__codelineno-6-17" name="__codelineno-6-17"></a>        <span class="s2">&quot;audio&quot;</span><span class="p">:</span> <span class="n">audio_encoder_plugin</span><span class="p">,</span>
<a id="__codelineno-6-18" name="__codelineno-6-18"></a>    <span class="p">},</span>
<a id="__codelineno-6-19" name="__codelineno-6-19"></a>    <span class="n">language_model_plugin</span><span class="o">=</span><span class="n">language_model_plugin</span><span class="p">,</span>
<a id="__codelineno-6-20" name="__codelineno-6-20"></a>    <span class="o">...</span>
<a id="__codelineno-6-21" name="__codelineno-6-21"></a><span class="p">)</span>
</code></pre></div></td></tr></table></div>
The number of total ranks in the example above is 27 (2*1*1 + 1*1*1 + 4*2*3).
If 54 GPUs join the training, there will be 2 data parallel replicas.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Cornstarch does not optimize rank assignment and leaves it to user responsibility.
The example above assigns 3 GPUs to the encoders and 8 GPUs to the LLM;
if each node has 8 GPUs, cross-node GPUs may be assigned to the LLM (5 GPUs from one node, and 3 GPUs from another one).</p>
</div>
<h3 id="modality-parallelism">Modality Parallelism</h3>
<p>Cornstarch executes multiple modality encoders in parallel, as there is no dependency between them.
By using <code>cornstarch.plugin.multimodal_parallel_plugin.MultimodalParallelPlugin</code>, modality encoders will be assigned to different devices and executed separately.</p>
<p>If you do not want to parallelize them, consider using <code>cornstarch.plugin.encoders_colocated_plugin.EncodersColocatedPlugin</code>, which colocates multiple modality encoders into the same GPUs and execute them sequentially.</p>
<h2 id="running-parallelized-module">Running Parallelized Module</h2>
<p>Pipeline parallelism interleaves forward passes and backward passes; therefore existing code for training (<code>loss = model(**inputs); loss.backward()</code>) is not compatible.
You have to use <code>Booster.execute_pipeline()</code> API to run the model:</p>
<div class="language-py highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-7-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-7-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-7-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-7-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-7-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-7-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-7-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-7-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-7-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-7-10">10</a></span>
<span class="normal"><a href="#__codelineno-7-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="n">outputs</span> <span class="o">=</span> <span class="n">booster</span><span class="o">.</span><span class="n">execute_pipeline</span><span class="p">(</span>
<a id="__codelineno-7-2" name="__codelineno-7-2"></a>    <span class="n">dataloader_iterator</span><span class="p">,</span>
<a id="__codelineno-7-3" name="__codelineno-7-3"></a>    <span class="n">model</span><span class="p">,</span>
<a id="__codelineno-7-4" name="__codelineno-7-4"></a>    <span class="n">crierion</span><span class="p">,</span>
<a id="__codelineno-7-5" name="__codelineno-7-5"></a>    <span class="n">optimizer</span><span class="p">,</span>
<a id="__codelineno-7-6" name="__codelineno-7-6"></a>    <span class="n">return_loss</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-7-7" name="__codelineno-7-7"></a>    <span class="n">return_outputs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-7-8" name="__codelineno-7-8"></a><span class="p">)</span>
<a id="__codelineno-7-9" name="__codelineno-7-9"></a>
<a id="__codelineno-7-10" name="__codelineno-7-10"></a><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<a id="__codelineno-7-11" name="__codelineno-7-11"></a><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<p>Refer to <a href="https://colossalai.org/docs/basics/booster_api#usage">Colossal-AI Booster API</a> and examples for more details about the arguments.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2025 Cornstarch team
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "search.suggest", "navigation.tabs", "navigation.tabs.sticky", "navigation.top"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
    
  </body>
</html>